#basic knowledge

1. 机器学习算法类型

    1. 监督式学习
        
        工作原理：此类算法有一个目标/输出变量（依赖变量），该值是通过一组预测因子（独立变量）推测出来的。通过这些预测因子，我们生成方程式得出输入与期望输出的对应关系。整个训练过程会持续到模型能通过训练数据达到一定的精确度。这类监督式学习算法有：回归算法，决策树，随机森林，邻近算法（KNN） 和逻辑回归算法等。
    
    2. 非监督式学习
        
        工作原理：此类算法，没有目标或预期输出变量。而是用于聚集不同的组别，其被广泛的应用于根据不同设定对客户人群进行分类。这类非监督式算法有：关联规则（Apriori algorithm），K均值聚类算法。

    3. 增强式学习

        运用这类算法，机器被训练成为能都做出特定的决策。机器被暴露于一个环境，它在其中通过不断的尝试与错误训练自己。这种机器学习通过过去的经验来试图捕捉最优解来做出最准确的商业决策。这类增强式算法有：马可夫决策过程。

2. 机器学习问题的组成

    机器学习主要是由三部分组成，即：表示(模型)、评价(策略)和优化(算法)。
    ![](/assets/20141102144824031.jpg)

    1. 表示(或者称为：模型)：
    
    **Representation表示主要做的就是建模，故可以称为模型**。模型要完成的主要工作是转换：将实际问题转化成为计算机可以理解的问题，就是我们平时说的建模。类似于传统的计算机学科中的算法，数据结构，如何将实际的问题转换成计算机可以表示的方式。
    2. 评价(或者称为：策略)：**J常说的性能度量就是性能评价的意思**
    
    **Evalution评价的目标是判断已建好的模型的优劣。**对于第一步中建好的模型，**评价是一个指标**，用于表示模型的优劣。这里就会是一些评价的指标以及一些评价函数的设计。
    有的问题可以直接基于设定的性能度量直接做最优化，得出该问题的一般求解模型。
    比如回归任务最常用的性能度量就是均方误差，目标就是让均方误差最小，这就直接转化成了一个最优化问题。
    其他一些常用的有错误率与精度、查准查全率、ROC与AOC等。
    
    3. 优化(或者称为：算法)：

    **Optimization优化的目标是评价的函数，我们是希望能够找到最好的模型，也就是说评价最高的模型。**
    
3. 选定模型

如果涉及到分类，可以参考的模型有线性回归及其非线性扩展、决策树、神经网络、支持向量机SVM、规则学习等

如果是回归问题，可以认为是分类的连续形式，方法便是以上模型的变种或扩展

如果涉及到概率，可以参考的有神经网络、贝叶斯、最大似然、EM、概率图、隐马尔科夫模型、强化学习等



