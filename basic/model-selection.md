# 模型选择

模型选择核心思想就是从某个模型类中选择最佳模型。当我们使用一种新的学习模型或者算法时，那么可是使用交叉验证来对模型进行评价。

下面伪代码表示了模型选择的**一般流程**。在这个算法中，最重要的就是第三个步骤中的误差评价。**记住此流程**。

1. 准备候选的$$\ell$$个模型：$$M_{1},\cdot\cdot\cdot,M_{\ell}$$。

2. 对每个模型$$M_{1},\cdot\cdot\cdot, M_{\ell}$$求解它的学习结果。

3. 对每个学习结果的误差$$e_{1},\cdot\cdot\cdot,e_{\ell}$$进行计算。这里可以使用交叉验证方法。

4. 选择误差$$e_{1},\cdot\cdot\cdot,e_{\ell}$$最小的模型作为最终的模型。


# 交叉验证

1. **Holdout验证或称为简单交叉验证**

  **方法为将原始数据随机分为两组,一组做为训练集,一组做为验证集**,利用训练集训练分类器,然后**利用验证集验证模型,记录最后的分类准确率**为此HoldOutMethod下分类器的性能指标。

  优点是简单，只需随机把原始数据分为两组即可；

  缺点为一般来说，Holdout验证并非一种交叉验证，因为数据并没有交叉使用。 随机从最初的样本中选出部分，形成交叉验证数据，而剩余的就当做训练数据。 一般来说，少于原本样本三分之一的数据被选做验证数据。

2. **K-fold cross-validation**

  **方法为初始采样分割成K个子样本，一个单独的子样本被保留作为验证模型的数据，其他K-1个样本用来训练**。交叉验证重复K次，每个子样本验证一次，**平均K次的结果**或者使用其它结合方式，最终得到一个单一估测。

  优点是可以有效的避免过学习以及欠学习状态的发生。**10折交叉验证是最常用的**。

  缺点是训练和测试次数过多。

3. **留一验证**

  方法是只使用原本样本中的一项来当做验证资料，而剩余的则留下来当做训练资料。 这个步骤一直持续到每个样本都被当做一次验证资料。事实上，这等同于 K-fold 交叉验证是一样的，只是这里的K被设置为原本样本个数。


# 交叉验证的一个目的是为了验证模型是否过拟合


1. 过拟合产生的原因

    1. 因为参数太多，会导致我们的模型复杂度上升，容易过拟合。

    2. 权值学习迭代次数足够多(Overtraining),拟合了训练数据中的噪声和训练样例中没有代表性的特征。

2. 过拟合的解决方法，**记住这些方法**。

    1. **减少特征**

    2. **正则化**

    3. **交叉验证法**
        


