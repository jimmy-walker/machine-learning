#模型选择
模型选择核心思想就是从某个模型类中选择最佳模型。当我们使用一种新的学习模型或者算法时，那么可是使用交叉验证来对模型进行评价。

下面伪代码表示了模型选择的**一般流程**。在这个算法中，最重要的就是第三个步骤中的误差评价。**记住此流程**。

1. 准备候选的$$\ell$$个模型：$$M_{1},\cdot\cdot\cdot,M_{\ell}$$。

2. 对每个模型$$M_{1},\cdot\cdot\cdot, M_{\ell}$$求解它的学习结果。

3. 对每个学习结果的误差$$e_{1},\cdot\cdot\cdot,e_{\ell}$$进行计算。这里可以使用交叉验证方法。

4. 选择误差$$e_{1},\cdot\cdot\cdot,e_{\ell}$$最小的模型作为最终的模型。

#交叉验证

1. **Holdout验证或称为简单交叉验证**

    **方法为将原始数据随机分为两组,一组做为训练集,一组做为验证集,利用训练集训练分类器,然后利用验证集验证模型,记录最后的分类准确率为此HoldOutMethod下分类器的性能指标**。

    优点是简单，只需随机把原始数据分为两组即可；
    
    缺点为一般来说，Holdout验证并非一种交叉验证，因为数据并没有交叉使用。 随机从最初的样本中选出部分，形成交叉验证数据，而剩余的就当做训练数据。 一般来说，少于原本样本三分之一的数据被选做验证数据。

2. **K-fold cross-validation**

    **方法为初始采样分割成K个子样本，一个单独的子样本被保留作为验证模型的数据，其他K-1个样本用来训练。交叉验证重复K次，每个子样本验证一次，平均K次的结果或者使用其它结合方式，最终得到一个单一估测**。
    
    优点是可以有效的避免过学习以及欠学习状态的发生。**10折交叉验证是最常用的**。

    缺点是训练和测试次数过多。

3. 

    